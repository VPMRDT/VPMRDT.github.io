<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="VPMRDT - Virtual Production Mixed Reality Digital Twin">
  <meta name="keywords" content="Virtual Producion, Cinematography, Lighting">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>VPMRDT 
    </title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div> -->

  <!-- <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div> 
    </div>

  </div> -->
<!-- </nav> -->


<section class="hero">
        <div class="column has-text-centered">
              <h4 class="title is-4 publication-title" >A Collaborative Mixed Reality(MR) Digital Twin Framework for Virtual Production: <br>
                Optimizing Cross Department In Camera Visual Effects (ICVFX) Workflows, Training, and Planning Across Physical and Virtual Realities</h4>
    </div>
</section>

<section class="hero teaser">

  <div class="hero-body"> 
    <div class="column has-text-centered">
              <p>
                To merge physical and virtual worlds, our MR digital twin framework creates a <strong>shared synchronous/asynchronous space</strong> where digital twins of ICVFX equipment, prop and set scans, and motion captures enable previz, techviz, and stuntviz <strong>role-based interactive visualizations</strong>, culminating in final <strong>on-set overlays</strong> that enhance <strong>collaborative efficiency</strong> and <strong>training accessibility</strong>.
              </p><br>
              <h3 class="title is-5" >Mixed Reality Prototype Demo on LED Volume</h3>
    </div>
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <img src="./static/images/Study_1.JPG"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> 
        </div>
        <div class="item item-chair-tp">
          <img src="./static/images/Study_2.JPG"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> 
        </div>
        <div class="item item-shiba">
          <img src="./static/images/Study_3.JPG"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> 
        </div>
        <div class="item item-fullbody">
          <img src="./static/images/Study_4.JPG"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> 
        </div>
        <div class="item item-blueshirt">
          <img src="./static/images/Study_5.JPG"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> 
        </div>
        <div class="item item-mask">
          <img src="./static/images/Study_6.JPG"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> 
        </div>
        <div class="item item-coffee">
          <img src="./static/images/Study_7.JPG"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> 
        </div>
        <div class="item item-toby">
          <img src="./static/images/Study_8.JPG"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> 
        </div>
      </div>
    </div>
    <div class="column has-text-centered">
             <h3 class="title is-5">Mixed Reality Prototype Demo on LED Volume: Meta Quest 3 View</h3> 
    </div>
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <iframe width="450" height="253" src="https://www.youtube.com/embed/8lPF8Fx60RA?autoplay=1&loop=1" title="HMD 4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

        </div>
        <div class="item item-chair-tp">
          <iframe width="450" height="253" src="https://www.youtube.com/embed/uOpAx-fZCUE?autoplay=1&loop=1" title="HMD 2" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

        </div>
        <div class="item item-shiba">
          <iframe width="450" height="253" src="https://www.youtube.com/embed/5N7wAkVTtY0?autoplay=1&loop=1" title="HMD 6" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
        <div class="item item-fullbody">
          <iframe width="450" height="253" src="https://www.youtube.com/embed/Q9G20z2EzAI?autoplay=1&loop=1" title="HMD 1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
        <div class="item item-blueshirt">
          <iframe width="450" height="253" src="https://www.youtube.com/embed/65fZcAOTIiQ?autoplay=1&loop=1" title="HMD 3" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
        <div class="item item-mask">
          <iframe width="450" height="253" src="https://www.youtube.com/embed/lyed_iy0Z0k?autoplay=1&loop=1" title="HMD 5" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
        <div class="item item-coffee">
          <iframe width="450" height="253" src="https://www.youtube.com/embed/Lh2E72Nd5ss?autoplay=1&loop=1" title="HMD 7" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
      </div>
    </div>

    <div class="column has-text-centered">
              <h3 class="title is-5">Mixed Reality Digital Twin Prototype Demo on Remote Location</h3>
    </div>
    <div class="columns is-centered"> 
        <div class="column">   
        <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/ICTfN5vEPBw"
                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div> 
        <div class="column">  
          <div class="publication-video">
              <iframe src="https://www.youtube.com/embed/1y_GKrftQFw"
                      frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
        </div>
      </div>

        <div class="column has-text-centered">
              <h3 class="title is-5">LED Wall Digital Twin: Layerd Representations Based on Pipeline Stage (Previz, Techviz, Stuntviz, Onset), Location, and Role</h3>
    </div>
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <img src="./static/images/LED_DT_Previz.png"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> 
        </div>
        <div class="item item-chair-tp">
          <img src="./static/images/LED_DT_TechViz.png"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> 
        </div>
        <div class="item item-shiba">
          <img src="./static/images/LED_DT_StuntVIz.png"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> 
        </div>
        <div class="item item-fullbody">
          <img src="./static/images/LED_DT_OnSet.png"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> 
        </div>
      </div>
    </div>

    <div class="column has-text-centered">
              <h3 class="title is-5" >Digital Twin Representations of Currently Available ARRA 216 and Red Studio Stages</h3>
    </div>
      
     <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <img src="./static/images/216.png"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> 
        </div>
        <div class="item item-chair-tp">
          <img src="./static/images/Red2.png"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> 
        </div>
        <div class="item item-shiba">
          <img src="./static/images/Red1.png"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> 
        </div>
        <div class="item item-fullbody">
          <img src="./static/images/Red2.png"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> 
        </div>
      </div>
    </div>     
    
    <div class="column has-text-centered">
      
      <h3 class="title is-5">Current ICVFX Pipeline</h3>
      <img src="./static/images/VP_Pipeline.png"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> <br>
      <h3 class="title is-5">Departmental Interactions: Left – Current Decentralized Interaction; Right – Shared Mixed Reality Digital Twin for Symmetric/Asymmetric Collaboration</h3>
      <img src="./static/images/Dept_Colab.png"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> <br>

      <h3 class="title is-5">Data Flow of The Current ICVFX Pipeline</h3>
      <img src="./static/images/CurrentPipleine.png"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> <br>

    </div>
<section class="section">
  <div class="columns is-centered">

    <!-- Left Column -->
    <div class="column">

      <h3 class="title is-4">Problem</h3>
      <p>
        Virtual production (VP) aims to merge physical and digital filmmaking, yet key departments still work in
        <strong>separate realities</strong>.
      </p>
      <ul style="list-style-type:disc; margin-left:1.5rem;">
        <li>The Art Department builds sets, props, and costumes.</li>
        <li>The Virtual Art Department (VAD) creates digital environments.</li>
        <li>Directors, DPs, and gaffers juggle both worlds without a single shared space.</li>
      </ul>
      <p>Collaboration relies on <strong>static artifacts</strong>: images, PDFs, video clips that lose crucial context such as:</p>
      <ul style="list-style-type:disc; margin-left:1.5rem;">
        <li>Set alignment</li>
        <li>Camera motion and rig reach</li>
        <li>Lighting layouts</li>
        <li>Precise measurements</li>
      </ul>
      <p>
        This siloed process leads to <strong>plan to execution drift</strong>, costly rework, and slower decision-making.
      </p><br>

      
      <h3 class="title is-4">Key Directions (Distilled)</h3>
      <ul style="list-style-type:disc; margin-left:1.5rem;">
        <li><strong>Role Aware Collaboration:</strong> Views, tools, and permissions tailored to Director, DP, Gaffer, VAD and Art roles across all pipeline stages.</li>
        <li><strong>Physical/Digital Parity:</strong> Keep physical assets and their digital twins perfectly mirrored so changes in one context instantly appear in the other.</li>
        <li><strong>Shared State &amp; Provenance:</strong> Maintain a single, restorable planning state with timestamps, authorship, and rationale supporting snapshots, versioning and comparison.</li>
        <li><strong>Live Safety &amp; Feasibility Intelligence:</strong> Provide real-time path clearance checks, collision heatmaps and rig-reach warnings before costly on-set issues occur.</li>
      </ul><br>

      <h3 class="title is-4">Next Steps</h3>
      <ul style="list-style-type:disc; margin-left:1.5rem;">
        <li><strong>Iterative development &amp; evaluation:</strong> Refine the Unreal plugin, integrate advanced constraint checks and telemetry, and run large-scale studies to measure how collaborative MR planning closes the gap between physical and virtual elements.</li>
        <li><strong>Production deployment:</strong> Validate the framework in live projects at the Virtual Production Institute.</li>
        <li><strong>Classroom role based training:</strong> Adapt the tools so students can practice collaborative planning when LED stages are busy or inaccessible.</li>
        <li><strong>Community release:</strong> Package the framework as an Unreal plugin so studios can create digital twins of their own facilities by entering equipment specifications or using integrated 3D scanning; future research will explore automatic twin generation from images or video.</li>
      </ul>

    </div>


    <!-- Right Column -->
    <div class="column">

      <h3 class="title is-4">Motivation</h3>
      <ul style="list-style-type:disc; margin-left:1.5rem;">
        <li>Provide a <strong>shared, context rich planning space</strong> where all departments can collaborate in real time.</li>
        <li>Preserve <strong>spatial and temporal accuracy</strong> from Previz through on-set stages.</li>
        <li>Align physical and virtual planning to <strong>reduce delays and costs</strong>.</li>
        <li>Support both <strong>live (synchronous)</strong> and <strong>remote (asynchronous)</strong> collaboration.</li>
      </ul>

      <h3 class="title is-4">Our Approach</h3>
      <ul style="list-style-type:disc; margin-left:1.5rem;">
        <li>Build a <strong>Mixed-Reality (MR) Digital Twin Framework</strong> inside Unreal Engine.</li>
        <li>Extend <strong>Virtual Scouting</strong> and <strong>Multi User Editing</strong> plugins with native MR passthrough and rich runtime interactions.</li>
        <li>Overlay <strong>true scale or desk scale digital twins</strong> of LED volumes, cameras, lighting gear, props, and motion-captured actors directly in the real environment.</li>
        <li>Enable every department to <strong>see, edit, and validate the same evolving plan</strong>, what is physical for one team becomes a faithful digital twin for another.</li>
        <li>Developed with feedback from <strong>Hollywood and commercial VP professionals</strong>, including supervisors and DPs with credits such as <em>The Mandalorian</em>.</li>
        <li>Demonstrated in a <strong>multi-user pilot</strong> on an LED stage using Meta Quest 3 headsets for collaborative, in-situ planning.</li>
      </ul><br>

      <h3 class="title is-4">Key Features</h3>
      <ul style="list-style-type:disc; margin-left:1.5rem;">
        <li>
          <strong>Unreal Native Mixed Reality Passthrough:</strong>
          Bring digital twins—such as LED stages or camera rigs—into any physical space, or place physical elements inside a virtual scene.
          Scale from desk size miniatures to full stage rehearsals without re-authoring assets.<br>
          <em>Example:</em> A director previews a miniature LED stage remotely, then walks onto the actual stage to rehearse the same setup in MR.
        </li>
        <li>
          <strong>Layered Digital Twin Stages:</strong>
          Toggle layers for context-specific visualizations: safety zones, rig reach limits, camera paths, animation curves and metadata overlays.
          Visual styles include PBR, schematic shading, gridded overlays, and color-coded Techviz (yellow/blue for practical vs. virtual).<br>
          <em>Example:</em> A DP enables the camera path and rig-reach layers to ensure a planned crane shot clears LED walls.
        </li>
        <li>
          <strong>Modular Physical Virtual Substitution:</strong>
          Replace or mix individual components—stands, lights, set pieces—between real and virtual worlds.<br>
          <em>Example:</em> A gaffer tests a real C-stand while positioning a virtual light with accurate photometrics.
        </li>
        <li>
          <strong>Role Aware Tools &amp; Pipeline Stage Interactions:</strong>
          Views, permissions and visual layers automatically adapt to user roles (Director, DP, Gaffer, VAD, Art) and production stages (Previz, Techviz, Stuntviz, Pre-light, On-set).<br>
          <em>Example:</em> A director plans blocking on a desk-scale model, then switches to room-scale MR to review actor motion and parallax; a VAD artist toggles to Techviz mode to inspect camera paths and decide what should be practical versus virtual.
        </li>
        <li>
          <strong>Live Feasibility &amp; Safety Intelligence:</strong>
          Real-time overlays provide collision heatmaps, rig reach envelopes, tracking bounds and no-go safety zones, giving early warnings before costly on-set issues arise.<br>
          <em>Example:</em> Before a stunt rehearsal, the system warns the stunt coordinator that a planned wire rig will collide with an overhead truss.
        </li>
        <li>
          <strong>Layered Annotations with Tag Library:</strong>
          Add time-stamped notes, sketches and pre-built tags such as camera move, light change or safety notice.
          Filter or export annotations by role or stage.<br>
          <em>Example:</em> During a remote Techviz session, the DP drops a “light change” tag and draws an arrow to indicate a spotlight adjustment.
        </li>
        <li>
          <strong>Versions, Variants &amp; Pre-Configured Kits:</strong>
          Branch and merge scene or shot versions, compare differences by layer, and promote approved elements to the master plan.
          Load pre-configured kits, for example, a 6×3 LED bay or a full Techviz stunt rig—for instant side-by-side comparison.<br>
          <em>Example:</em> The production designer toggles between day and night lighting plans in seconds.
        </li>
        <li>
          <strong>Exportable Shot Packages &amp; On-Set Playback:</strong>
          Export shot packages capturing lens/rig paths, timings, light plots, enabled layers and annotations.
          On set, crews can swap scenes or shots instantly, trigger camera moves, actor motion or lighting cues, and capture telemetry to flag deviations.<br>
          <em>Example:</em> When weather forces a sudden change, the DP reloads a saved shot package to re-cue lighting and camera moves in minutes.
        </li>
        <li>
          <strong>Rapid Digital Twin Creation:</strong>
          Build digital twins of ICVFX equipment by entering specs and dimensions, or capture props and sets using mobile photogrammetry.<br>
          <em>Example:</em> The art team scans a practical tree prop and drops it into the MR workspace to check shadow placement before construction.
        </li>
      </ul>

    </div>
  </div>
</section>


  </div>
    <div class="hero-body">   
      
    </div>
  
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    
  </div>
</section>


  <section class="section">
      <!-- <h3>Digital Twin of LED wall represented in USD Layers</h3>
      <img src="./static/images/USD DT Layers.png"
                    class="interpolation-image"
                    alt="Interpolate start reference image."/> <br>

       <div class="columns is-centered">  -->
    
        
  
        <!-- Visual Effects. -->
        <!-- <div class="column">
            <img src="./static/images/216.png"
                   class="interpolation-image"
                   alt="Interpolate start reference image."/>

            <img src="./static/images/Red2.png"
                   class="interpolation-image"
                   alt="Interpolate start reference image."/>

        </div>  -->
        <!--/ Visual Effects. -->
  
        <!-- Matting. -->
         <!-- <div class="column">
          
                <img src="./static/images/Red1.png"
                      class="interpolation-image"
                      alt="Interpolate start reference image."/>
                <img src="./static/images/Red3.png"
                      class="interpolation-image"
                      alt="Interpolate start reference image."/>
            
        </div> -->
      </div> 
  </section>

  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link"
           href="./static/videos/nerfies_paper.pdf">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="column has-text-centered">
            <p>
              This website is licensed under a <a rel="license"href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website.
            </p>
          </div>
        </div>
      </div>
    </div>

</footer>

</body>
</html>
